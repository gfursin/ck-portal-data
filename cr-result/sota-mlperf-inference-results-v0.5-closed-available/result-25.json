[
  {
    "accelerator": "NVIDIA Tesla T4",
    "accelerator_no": 8,
    "code": "https://github.com/mlperf/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "details": "https://github.com/mlperf/inference_results_v0.5/blob/master/closed/NVIDIA/systems/T4x8.json",
    "ff_d": "",
    "ff_e": "x",
    "ff_m": "",
    "ff_s": "x",
    "id": "Inf-0.5-27",
    "notes": "ECC off",
    "p_ic1_ms": 6320,
    "p_ic1_o": 141807,
    "p_ic1_s": 135072.99,
    "p_ic1_ss": "",
    "p_ic2_ms": 1920,
    "p_ic2_o": 44977.8,
    "p_ic2_s": 41546.64,
    "p_ic2_ss": "",
    "p_nmt_ms": "",
    "p_nmt_o": 2834.75,
    "p_nmt_s": 1581.2,
    "p_nmt_ss": 41.322,
    "p_od1_ms": 2624,
    "p_od1_o": 60871.6,
    "p_od1_s": 56620,
    "p_od1_ss": "",
    "p_od2_ms": 56,
    "p_od2_o": 1095.11,
    "p_od2_s": 1010.49,
    "p_od2_ss": 6.703,
    "processor": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "processor_no": 2,
    "seq_number": 25,
    "software": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3",
    "submitter": "NVIDIA",
    "system": "Supermicro 4029GP-TRT-OTO-28 8xT4 (T4x8)"
  }
]
